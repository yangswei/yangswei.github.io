---
layout: post
title: "K8s集群-fek插件"
date: 2018-10-24 
description: "fluentd+elasticsearch+kibana for k8s"
tag: k8s 
---   

> 安装插件前准备工作

github地址: [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)            
![](/images/posts/k8s-fek/1.png)      
如图,选择对应版本的k8s分支,然后下载对应的es,fluentd,kibana的yaml文件，一共6个文件。      
在github上提供了官方的image地址:      
``` 
    k8s.gcr.io/elasticsearch:v5.6.4
    k8s.gcr.io/fluentd-elasticsearch:v2.0.4
    docker.elastic.co/kibana/kibana:5.6.4
```      
这些镜像貌似都被墙了，可以翻墙将镜像下载到本地，然后调整yaml的iamge地址，或者找找一些大牛将这些镜像放到国内cdn提供下载的地址。      
另外在gihub里面提供了完整的dockerfile，可以自定义编辑镜像      
本人在使用时由于要使用额外的plugin，在fluentd的Gemfile中将要额外增加的插件添加进去，然后本地build镜像，另外两个镜像则是直接下载官方的再load到本地      
      
> 执行yaml文件前，一些修改       

其实fek的原理很简单：fluentd会根据配置文件`fluentd-es-configmap.yaml`指定的规则收集系统日志，然后按规定格式打到els中，kibana读取els日志前端展示      
第一步：      
    设置node节点的标签,只在标记了标签的节点上运行fluentd          
    ```
        kubectl get nodes
        kubectl label nodes nodenamexxx beta.kubernetes.io/fluentd-ds-ready=true
    ```      
第二步：      
    调整默认kibana的yaml文件,使用nodeport模式
    ![](/images/posts/k8s-fek/2.png)      

> fluentd的configmap

在kubenetes的github默认的配置文件中对于配置有非常详细的说明，这里我粗略的翻译一下，后面具体讲下当时我们使用的配置项
config中有三个标签：source,match,filter。source的标签指定数据源，filter的标签对数据匹配处理，match也是匹配，一般作为末尾指定输出       

- 在Linux系统上systemd系统来管理kubernetes服务，并且journal系统会接管服务程序的输出日志，可以通过`systemctl status xxx`或`journalctl -u xxx -f`来查看kubernetes服务的日志.    

| k8s组件 | 日志内容 |
| ------ | :------: | 
| k8s-apiserver | 无 |
| kube-controller-manager | pod扩容或rc |
| kube-scheduler | pod扩容或rc |
| kubelet | pod周期相关：创建、停止 |
| etcd | 无 |
git 
我们以kubelet日志为例，执行`journalctl -u kubelet -f`可以看到传输到fluentd的源日志数据的格式是日期+节点+xx+container名+image名+port+xxx+xxx+

 

> apply所有yaml文件

查看所有pod启动情况：`kubectl get pods -n kube-system -o wide|grep -E 'elasticsearch|fluentd|kibana'`       
查看service情况： `kubectl get service  -n kube-system|grep -E 'elasticsearch|kibana'`      

> 在kibana中创建索引

按默认的所有日志打到elasticsearch是按默认的带日期tag或者全部打到els的某个索引中。      
可以在fluentd中设置，将日志按服务名分别打到els对应的索引中，最后在els中收集到的日志是按服务名索引来建立的      
在kibana中按appname* 作为`Create Index Pattern`       
![](/images/posts/k8s-fek/3.png)



> 注意
       
fek主要的是：
    fluentd中如何定义日志源source
    将源日志通过match,filter最终按标准输入到elasticsearch中去      
从源获取的日志，打上tag，输入到els中，fluentd的configmap中input.conf指定source文件，并打上tag，output.conf中按tag值匹配对应的index_name存入elasticsearch中            
另外      
      默认的els设置的limits最好调整一下，默认的不够用。els崩会导致kibana中报错。     
      如果els经常报错，可以将els从k8s中移除，单独运行els然后在kibana和fluentd中将els的地址修改为启动的地址      
    kibana中加上：      
```      
    - name: XPACK_SECURITY_ENABLED       
        value: "false"       
```     

els启动文件：

```      
version: '2'      
services:      
  elasticsearch:      
    image: docker.elastic.co/elasticsearch/elasticsearch:5.6.2      
    expose:      
      - 9200      
    ports:     
      - "9200:9200"      
    environment:      
      - bootstrap.memory_lock=true      
      - xpack.security.enabled=false      
      - "ES_JAVA_OPTS=-Xms8G -Xmx8G"      
    ulimits:      
      memlock:      
        soft: -1      
        hard: -1      
    volumes:      
      - /opt/Elasticsearch/data:/usr/share/elasticsearch/data      
```       
