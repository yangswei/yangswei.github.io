---
layout: post
title: "K8s集群-fek插件生产实践"
date: 2018-10-24  
description: "fluentd+elasticsearch+kibana for k8s"
tag: Docker  
---  

## 安装插件前准备工作

github地址: [https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)  
路径为kubenetes/cluster/addons/fluentd-elasticsearch  

选择对应版本的k8s分支,然后下载对应的es,fluentd,kibana的yaml文件,一共6个文件。  
在github上提供了官方的image地址:  

```bash
k8s.gcr.io/elasticsearch:v5.6.4
k8s.gcr.io/fluentd-elasticsearch:v2.0.4
docker.elastic.co/kibana/kibana:5.6.4
```  

这些镜像貌似都被墙了,可以翻墙将镜像下载到本地,然后调整yaml的iamge地址,或者找找一些大牛将这些镜像放到国内cdn提供下载的地址。  
另外在gihub里面提供了完整的dockerfile,可以自定义编辑镜像,如果要使用额外的plugin插件,则在fluentd的Gemfile中将要额外增加的插件添加进去,然后本地build镜像。  
      
### 调整文件       

fluentd会根据配置文件`fluentd-es-configmap.yaml`指定的规则收集系统日志,然后按规定格式打到els中,kibana读取els日志前端展示   
Fluentd+elasticsearch+kibana中配置相对复杂一些的就是fluentd。
设置node节点的标签,只在标记了标签的节点上运行fluentd  
`kubectl get nodes`  
`kubectl label nodes nodenamexxx beta.kubernetes.io/fluentd-ds-ready=true`  
  
调整默认kibana的yaml文件,设置type为NodePort然后指定nodeport  
调整elasticsearch的statefulset文件,调整limits&requests的cpu,按实际的需要来进行调整大小（至少2G+）  
`curl ip:9200/_cat/indices?v`  
内存不够时,索引的状态会**red**,单节点的els索引状态为**yellow**  

### 按实际需要调整fluentd的configmap

| k8s组件 | 日志内容 |
| ------ | :------: | 
| kube-controller-manager | pod扩容或rc |
| kube-scheduler | pod扩容或rc |
| kubelet | pod周期相关：创建、停止 |

k8s组件收集的日志是k8s集群的日志,实际的应用场景中,需要查看的是k8s集群中对应的服务打印出来的日志,在Linux系统上systemd系统来管理kubernetes服务,并且journal系统会接管服务程序的输出日志,可以通过`journalctl -u docker -o json-pretty -f`来查看服务的日志. 

```json
{
	"__CURSOR" : "xxx",
	"__REALTIME_TIMESTAMP" : "xxx",
	"__MONOTONIC_TIMESTAMP" : "xx",
	"_BOOT_ID" : "xx",
	"PRIORITY" : "x",
	"_UID" : "0",
	"_GID" : "0",
	"_CAP_EFFECTIVE" : "xx",
	"_SYSTEMD_CGROUP" : "xx",
	"_MACHINE_ID" : "xx",
	"_HOSTNAME" : "xxx",
	"_TRANSPORT" : "xx",
	"SYSLOG_FACILITY" : "3",
	"_STREAM_ID" : "xx",
	"SYSLOG_IDENTIFIER" : "xx",
	"_PID" : "xx",
	"_COMM" : "dockerd-current",
	"_EXE" : "xx",
	"_CMDLINE" : "xx",
	"_SYSTEMD_UNIT" : "xx",
	"MESSAGE" : "xx"
}
```
 
fluentd-configmap指定源数据,匹配所有系统日志中_COMM值为`dockerd-current`的日志记录为源日志数据
输出部分说明,我所使用的环境中用到的插件有：
- rewrite_tag_filter
- kubernetes_metadata
- record_transformer

```
<source>
@type systemd
path /var/log/journal
filters [{ "_COMM": "dockerd-current" }]
#pos_file /tmp/fluentd/journal.pos
tag journal
strip_underscores true
read_from_head true
</source>
```

匹配journal的日志数据,将container_name以k8s_开头的日志打上tag标签
注意：官方的image中没有安装rewrite_tag_filter插件,在dockerfile指定的Gemfile添加
`gem 'fluent-plugin-rewrite-tag-filter','~>2.1.0'`

```yml
<match journal>
@type rewrite_tag_filter
<rule>
key CONTAINER_NAME
pattern ^k8s_
tag kubernetes.journal.container
</rule>
log_level trace
</match>
```

根据上文打好的标签,过滤标签,将kubernetes.xx的标签匹配后,
通过kubernetes_metadata将日志数据格式化

```yml
<filter kubernetes.**>
@type kubernetes_metadata
use_journal true
</filter>
同上,匹配标签,使用record_transformer插件,添加topic
<filter kubernetes.**>
@type record_transformer
enable_ruby
<record>
topic k8s-${record["kubernetes"]["container_name"]}
</record>
</filter>
最后匹配所有,将日志按index_name保存到els中
<match **>
@id elasticsearch
@type elasticsearch
@log_level info
#只有tag_key是topic的日志才会输入到els中
include_tag_key true
tag_key topic
host elasticsearch-logging
port 9200
#logstash_format true
#将日志的topic匹配索引的key[这里key的值定义为topic],
#如果日志的topic=索引的key,则将对应的日志打入对应的索引中
target_index_key topic
index_name logstash-${topic}
<buffer>
@type file
path /var/log/fluentd-buffers/kubernetes.system.buffer
flush_mode interval
retry_type exponential_backoff
flush_thread_count 2
flush_interval 5s
retry_forever
retry_max_interval 30
chunk_limit_size 2M
queue_limit_length 8
overflow_action block
</buffer>
</match>
```

插件作用：
`rewrite_tag_filter`插件是从source源匹配的日志中,过滤找到`CONTAINER_NAME`以k8s开头的日志,将过滤出来的日志打上tag
另外两个插件分别是将源文件进行格式处理
metadata将日志中添加对应kubenetes的信息,类似容器名,namespace名等,record则是添加一个topic字段,topic名为k8s-容器的pod名

最后在match中将日志按index=topic的规则写到对应的index中（index的值即为容器名:k8s-appname-xxx)
在kibana中即能够定义`Index Patterns`的值为k8s-appname*

### 检验

查看所有pod启动情况：
`kubectl get pods -n kube-system -o wide|grep -E 'elasticsearch|fluentd|kibana'`       
查看service情况：     
`kubectl get service  -n kube-system|grep -E 'elasticsearch|kibana'`      

### 注意
            
如果els经常报错,可以将els相关的组件从k8s中移除,单独运行elasticsearch。
然后在修改kibana和fluentd中指定的elasticsearch地址,指定elasticsearch的位置。       
        
kibana中加上：      
```      
- name: XPACK_SECURITY_ENABLED       
    value: "false"       
```       
elasticsearch的docker-compose文件
```      
version: '2'      
services:      
  elasticsearch:      
    image: docker.elastic.co/elasticsearch/elasticsearch:5.6.2      
    expose:      
      - 9200      
    ports:     
      - "9200:9200"      
    environment:      
      - bootstrap.memory_lock=true      
      - xpack.security.enabled=false      
      - "ES_JAVA_OPTS=-Xms8G -Xmx8G"      
    ulimits:      
      memlock:      
        soft: -1      
        hard: -1      
    volumes:      
      - /Elasticsearch/data:/usr/share/elasticsearch/data      
```       
